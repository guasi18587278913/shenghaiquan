#!/usr/bin/env python3
"""
åˆ†æCSVæ•°æ®å’Œæ•°æ®åº“çš„å·®å¼‚ï¼Œæ‰¾å‡ºé¢å¤–çš„22ä¸ªç”¨æˆ·
"""

import json
import csv
import os
import sqlite3
from datetime import datetime
from collections import defaultdict, Counter

def read_csv_users(csv_path):
    """è¯»å–CSVæ–‡ä»¶ï¼Œè·å–æ‰€æœ‰æœ‰æ•ˆçš„ç”¨æˆ·ååˆ—è¡¨"""
    users = []
    
    # ä½¿ç”¨csvæ¨¡å—æ¥æ­£ç¡®å¤„ç†åŒ…å«æ¢è¡Œç¬¦å’Œå¼•å·çš„CSVæ–‡ä»¶
    with open(csv_path, 'r', encoding='utf-8-sig') as file:
        csv_reader = csv.reader(file)
        
        # è·³è¿‡æ ‡é¢˜è¡Œ
        header = next(csv_reader, None)
        
        for i, row in enumerate(csv_reader, start=2):  # ä»ç¬¬2è¡Œå¼€å§‹ï¼ˆè·³è¿‡æ ‡é¢˜ï¼‰
            if len(row) >= 13 and row[0].isdigit():  # ç¡®ä¿æ˜¯æœ‰æ•ˆæ•°æ®è¡Œ
                try:
                    # æ˜Ÿçƒç¼–å·åœ¨ç¬¬1åˆ—ï¼ˆç´¢å¼•0ï¼‰
                    star_id = row[0].strip()
                    # å¾®ä¿¡æ˜µç§°åœ¨ç¬¬2åˆ—ï¼ˆç´¢å¼•1ï¼‰
                    wechat_name = row[1].strip()
                    # æ˜Ÿçƒæ˜µç§°åœ¨ç¬¬3åˆ—ï¼ˆç´¢å¼•2ï¼‰
                    star_name = row[2].strip()
                    # æ‰‹æœºå·åœ¨ç¬¬12åˆ—ï¼ˆç´¢å¼•11ï¼‰
                    phone = row[11].strip() if len(row) > 11 else ''
                    # å¾®ä¿¡å·åœ¨ç¬¬13åˆ—ï¼ˆç´¢å¼•12ï¼‰
                    wechat_id = row[12].strip() if len(row) > 12 else ''
                    
                    # ä¼˜å…ˆä½¿ç”¨æ˜Ÿçƒæ˜µç§°ï¼Œå¦‚æœä¸ºç©ºåˆ™ä½¿ç”¨å¾®ä¿¡æ˜µç§°
                    name = star_name if star_name else wechat_name
                    
                    if name:
                        users.append({
                            'star_id': star_id,
                            'name': name,
                            'wechat_name': wechat_name,
                            'star_name': star_name,
                            'phone': phone,
                            'wechat_id': wechat_id,
                            'line_number': i,
                            'raw_line': ','.join(row[:5]) + '...' if len(','.join(row)) > 100 else ','.join(row)
                        })
                except Exception as e:
                    print(f"  è­¦å‘Š: ç¬¬{i}è¡Œè§£æå¤±è´¥: {e}")
    
    return users

def get_db_users(db_path):
    """ä»æ•°æ®åº“è·å–æ‰€æœ‰ç”¨æˆ·ä¿¡æ¯"""
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # è·å–æ‰€æœ‰ç”¨æˆ·
    cursor.execute("""
        SELECT id, email, name, phone, role, createdAt, updatedAt
        FROM User
        ORDER BY createdAt
    """)
    
    users = []
    for row in cursor.fetchall():
        users.append({
            'id': row[0],
            'email': row[1],
            'name': row[2],
            'phone': row[3],
            'role': row[4],
            'created_at': row[5],
            'updated_at': row[6]
        })
    
    conn.close()
    return users

def analyze_extra_users(csv_users, db_users):
    """åˆ†æåœ¨æ•°æ®åº“ä¸­ä½†ä¸åœ¨CSVä¸­çš„ç”¨æˆ·"""
    # åˆ›å»ºå¤šä¸ªæŸ¥æ‰¾é›†åˆï¼Œæé«˜åŒ¹é…å‡†ç¡®æ€§
    csv_names = {user['name'].lower().strip() for user in csv_users}
    csv_wechat_names = {user['wechat_name'].lower().strip() for user in csv_users if user['wechat_name']}
    csv_star_names = {user['star_name'].lower().strip() for user in csv_users if user['star_name']}
    csv_phones = {user['phone'].strip() for user in csv_users if user['phone'] and user['phone'] != 'æ— '}
    csv_wechat_ids = {user['wechat_id'].lower().strip() for user in csv_users if user['wechat_id']}
    
    # åˆå¹¶æ‰€æœ‰åç§°é›†åˆ
    all_csv_names = csv_names | csv_wechat_names | csv_star_names
    
    # æ‰¾å‡ºé¢å¤–çš„ç”¨æˆ·
    extra_users = []
    seed_users = []  # ç§å­æ•°æ®ç”¨æˆ·
    matched_users = []  # åŒ¹é…åˆ°çš„ç”¨æˆ·
    
    for db_user in db_users:
        name_lower = db_user['name'].lower().strip() if db_user['name'] else ''
        email_lower = db_user['email'].lower().strip() if db_user['email'] else ''
        phone = db_user['phone'].strip() if db_user['phone'] else ''
        
        # æ£€æŸ¥æ˜¯å¦åœ¨CSVä¸­
        in_csv = False
        match_type = None
        
        # 1. åç§°åŒ¹é…ï¼ˆæ£€æŸ¥æ‰€æœ‰å¯èƒ½çš„åç§°ï¼‰
        if name_lower in all_csv_names:
            in_csv = True
            match_type = 'name'
        # 2. æ‰‹æœºå·åŒ¹é…
        elif phone and phone in csv_phones:
            in_csv = True
            match_type = 'phone'
        # 3. å¾®ä¿¡IDåŒ¹é…ï¼ˆå‡è®¾emailå¯èƒ½åŒ…å«å¾®ä¿¡IDï¼‰
        elif email_lower and any(wechat_id in email_lower for wechat_id in csv_wechat_ids if wechat_id):
            in_csv = True
            match_type = 'wechat_id'
        
        if in_csv:
            matched_users.append(db_user)
        else:
            # åˆ¤æ–­æ˜¯å¦æ˜¯ç§å­æ•°æ®ï¼ˆç³»ç»Ÿå†…ç½®ç”¨æˆ·ï¼‰
            if ('student' in email_lower or 'admin' in email_lower or 
                'assistant' in email_lower or 'test' in email_lower or
                db_user['role'] != 'USER'):
                seed_users.append(db_user)
            else:
                extra_users.append(db_user)
    
    return extra_users, seed_users, matched_users

def analyze_user_patterns(users):
    """åˆ†æç”¨æˆ·çš„ç‰¹å¾æ¨¡å¼"""
    patterns = {
        'total': len(users),
        'by_role': Counter(user['role'] for user in users),
        'by_email_domain': defaultdict(int),
        'by_creation_date': defaultdict(int),
        'email_patterns': defaultdict(int),
        'users': []
    }
    
    for user in users:
        # åˆ†æé‚®ç®±åŸŸå
        if user['email'] and '@' in user['email']:
            domain = user['email'].split('@')[1]
            patterns['by_email_domain'][domain] += 1
        
        # åˆ†æåˆ›å»ºæ—¥æœŸ
        if user['created_at']:
            try:
                # å¤„ç†æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
                if isinstance(user['created_at'], (int, float)) or user['created_at'].isdigit():
                    timestamp = int(user['created_at']) / 1000  # è½¬æ¢ä¸ºç§’
                    created_date = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d')
                else:
                    # å¦‚æœæ˜¯æ—¥æœŸå­—ç¬¦ä¸²
                    created_date = user['created_at'].split()[0]
                patterns['by_creation_date'][created_date] += 1
            except:
                pass
        
        # åˆ†æé‚®ç®±æ¨¡å¼
        if user['email']:
            if user['email'].count('.') > 1:
                patterns['email_patterns']['multiple_dots'] += 1
            if any(char.isdigit() for char in user['email'].split('@')[0]):
                patterns['email_patterns']['contains_numbers'] += 1
            if user['email'].startswith('student'):
                patterns['email_patterns']['starts_with_student'] += 1
        
        # ä¿å­˜ç”¨æˆ·è¯¦ç»†ä¿¡æ¯
        patterns['users'].append({
            'id': user['id'],
            'name': user['name'],
            'email': user['email'],
            'phone': user['phone'],
            'role': user['role'],
            'created_at': user['created_at']
        })
    
    # è½¬æ¢Counterå¯¹è±¡ä¸ºå­—å…¸
    patterns['by_role'] = dict(patterns['by_role'])
    patterns['by_email_domain'] = dict(patterns['by_email_domain'])
    patterns['by_creation_date'] = dict(patterns['by_creation_date'])
    patterns['email_patterns'] = dict(patterns['email_patterns'])
    
    return patterns

def main():
    # è®¾ç½®è·¯å¾„
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    csv_path = os.path.join(base_dir, 'data', 'æµ·å¤–AIäº§å“ åå• .csv')
    db_path = os.path.join(base_dir, 'prisma', 'dev.db')
    output_path = os.path.join(base_dir, 'extra-users-analysis.json')
    
    print("ğŸ” å¼€å§‹åˆ†æCSVå’Œæ•°æ®åº“å·®å¼‚...")
    
    # è¯»å–æ•°æ®
    print("ğŸ“„ è¯»å–CSVæ–‡ä»¶...")
    csv_users = read_csv_users(csv_path)
    print(f"  CSVä¸­æœ‰æ•ˆç”¨æˆ·æ•°: {len(csv_users)}")
    
    print("ğŸ’¾ è¯»å–æ•°æ®åº“...")
    db_users = get_db_users(db_path)
    print(f"  æ•°æ®åº“æ€»ç”¨æˆ·æ•°: {len(db_users)}")
    
    # æ‰¾å‡ºé¢å¤–ç”¨æˆ·
    print("\nğŸ” æŸ¥æ‰¾é¢å¤–ç”¨æˆ·...")
    extra_users, seed_users, matched_users = analyze_extra_users(csv_users, db_users)
    
    print(f"  åŒ¹é…åˆ°çš„ç”¨æˆ·: {len(matched_users)}")
    print(f"  ç§å­æ•°æ®ç”¨æˆ·: {len(seed_users)}")
    print(f"  é¢å¤–ç”¨æˆ·æ•°: {len(extra_users)}")
    
    # åˆ†æé¢å¤–ç”¨æˆ·ç‰¹å¾
    print("\nğŸ“Š åˆ†æé¢å¤–ç”¨æˆ·ç‰¹å¾...")
    extra_analysis = analyze_user_patterns(extra_users)
    seed_analysis = analyze_user_patterns(seed_users)
    
    # æ±‡æ€»ç»“æœ
    result = {
        'summary': {
            'csv_users': len(csv_users),
            'db_users': len(db_users),
            'matched_users': len(matched_users),
            'seed_users': len(seed_users),
            'extra_users': len(extra_users),
            'expected_extra': len(db_users) - len(csv_users),
            'analysis_time': datetime.now().isoformat()
        },
        'extra_users': extra_analysis,
        'seed_users': seed_analysis,
        'csv_sample': {
            'first_5_users': csv_users[:5] if csv_users else [],
            'total': len(csv_users)
        },
        'verification': {
            'total_check': len(matched_users) + len(seed_users) + len(extra_users) == len(db_users),
            'expected_csv_imports': len(csv_users),
            'actual_matched': len(matched_users),
            'difference': len(csv_users) - len(matched_users)
        }
    }
    
    # ä¿å­˜ç»“æœ
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… åˆ†æå®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    
    # æ‰“å°æ‘˜è¦
    print("\nğŸ“‹ åˆ†ææ‘˜è¦:")
    print(f"  CSVç”¨æˆ·æ€»æ•°: {len(csv_users)}")
    print(f"  æ•°æ®åº“ç”¨æˆ·æ€»æ•°: {len(db_users)}")
    print(f"  ç§å­æ•°æ®: {len(seed_users)}")
    print(f"  é¢å¤–ç”¨æˆ·: {len(extra_users)}")
    print(f"\n  é¢„æœŸå·®å¼‚ (DB - CSV): {len(db_users) - len(csv_users)}")
    print(f"  å®é™…é¢å¤–ç”¨æˆ·: {len(extra_users)}")
    print(f"  å·®å¼‚è§£é‡Š: {len(seed_users)} ä¸ªç§å­ç”¨æˆ· + {len(extra_users)} ä¸ªé¢å¤–ç”¨æˆ·")
    
    if extra_analysis['by_role']:
        print(f"\n  é¢å¤–ç”¨æˆ·è§’è‰²åˆ†å¸ƒ:")
        for role, count in extra_analysis['by_role'].items():
            print(f"    {role}: {count}")
    
    if extra_analysis['by_email_domain']:
        print(f"\n  é¢å¤–ç”¨æˆ·é‚®ç®±åŸŸååˆ†å¸ƒ:")
        for domain, count in sorted(extra_analysis['by_email_domain'].items(), 
                                   key=lambda x: x[1], reverse=True)[:5]:
            print(f"    {domain}: {count}")

if __name__ == '__main__':
    main()